{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MOBULA_DATA_FILE = \"./pipeline/mobula-data.json\"\n",
    "LUNARCRUSH_DATA_FILE = \"./pipeline/lunarcrush-data.json\"\n",
    "\n",
    "lunarcrush_headers = {'Authorization': 'Bearer deb9mcyuk3wikmvo8lhlv1jsxnm6mfdf70lw4jqdk'}\n",
    "mobula_headers = {\"Authorization\": \"e26c7e73-d918-44d9-9de3-7cbe55b63b99\"}\n",
    "lunarcrush_base_url = \"https://lunarcrush.com/api4\"\n",
    "mobula_base_url = \"https://production-api.mobula.io/api/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data cycle...\n",
      "Fetched 4 unique endpoints from Supabase.\n",
      "Fetching data from: https://lunarcrush.com/api4/public/coins/AAVE/v1 (Provider: lunarcrush)\n",
      "Successfully fetched data from https://lunarcrush.com/api4/public/coins/AAVE/v1 in 1.21 seconds.\n",
      "Data saved to local file for endpoint: https://lunarcrush.com/api4/public/coins/AAVE/v1\n",
      "Fetching data from: https://lunarcrush.com/api4/public/coins/list/v2?filter=DAO&sort=galaxy_score&limit=20 (Provider: lunarcrush)\n",
      "Successfully fetched data from https://lunarcrush.com/api4/public/coins/list/v2?filter=DAO&sort=galaxy_score&limit=20 in 0.74 seconds.\n",
      "Data saved to local file for endpoint: https://lunarcrush.com/api4/public/coins/list/v2?filter=DAO&sort=galaxy_score&limit=20\n",
      "Fetching data from: https://production-api.mobula.io/api/1/market/blockchain/pairs?blockchain=solana&sortBy=market_cap&sortOrder=desc (Provider: mobula)\n",
      "Successfully fetched data from https://production-api.mobula.io/api/1/market/blockchain/pairs?blockchain=solana&sortBy=market_cap&sortOrder=desc in 6.36 seconds.\n",
      "Data saved to local file for endpoint: https://production-api.mobula.io/api/1/market/blockchain/pairs?blockchain=solana&sortBy=market_cap&sortOrder=desc\n",
      "Fetching data from: https://production-api.mobula.io/api/1/market/multi-data?symbols=AAVE,INV,MKR (Provider: mobula)\n",
      "Successfully fetched data from https://production-api.mobula.io/api/1/market/multi-data?symbols=AAVE,INV,MKR in 0.90 seconds.\n",
      "Data saved to local file for endpoint: https://production-api.mobula.io/api/1/market/multi-data?symbols=AAVE,INV,MKR\n",
      "Data cycle finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MOBULA_DATA_FILE = \"./pipeline/mobula-data.json\"\n",
    "LUNARCRUSH_DATA_FILE = \"./pipeline/lunarcrush-data.json\"\n",
    "\n",
    "lunarcrush_headers = {'Authorization': 'Bearer deb9mcyuk3wikmvo8lhlv1jsxnm6mfdf70lw4jqdk'}\n",
    "mobula_headers = {\"Authorization\": \"e26c7e73-d918-44d9-9de3-7cbe55b63b99\"}\n",
    "lunarcrush_base_url = \"https://lunarcrush.com/api4\"\n",
    "mobula_base_url = \"https://production-api.mobula.io/api/1\"\n",
    "\n",
    "header_map = {\n",
    "    \"lunarcrush\": lunarcrush_headers,\n",
    "    \"mobula\": mobula_headers\n",
    "}\n",
    "\n",
    "base_urls = {\n",
    "    \"lunarcrush\": lunarcrush_base_url,\n",
    "    \"mobula\": mobula_base_url\n",
    "}\n",
    "\n",
    "\n",
    "supabase_url: str = os.environ.get(\"SUPABASE_PROJECT_URL\")\n",
    "supabase_key: str = os.environ.get(\"SUPABASE_ANON_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "\n",
    "def load_local_data(provider):\n",
    "    file_path = MOBULA_DATA_FILE if provider == \"mobula\" else LUNARCRUSH_DATA_FILE\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def save_local_data(provider, endpoint_data):\n",
    "    file_path = MOBULA_DATA_FILE if provider == \"mobula\" else LUNARCRUSH_DATA_FILE\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(endpoint_data, f, indent=2)\n",
    "\n",
    "def fetch_unique_endpoints_from_supabase():\n",
    "    try:\n",
    "        response = supabase.table('apis_to_call').select('endpoint').execute()\n",
    "        endpoints_data = response.data\n",
    "        unique_endpoints = set()\n",
    "        for item in endpoints_data:\n",
    "            endpoint = item.get('endpoint')\n",
    "            if endpoint:\n",
    "                unique_endpoints.add(endpoint)\n",
    "        return list(unique_endpoints)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during endpoint fetching from Supabase: {e}\")\n",
    "        return None\n",
    "\n",
    "def determine_provider(endpoint_path): # Changed parameter name to endpoint_path\n",
    "    if endpoint_path.startswith(\"/public\"): # Mobula endpoints start with /market or /coins\n",
    "        return \"lunarcrush\"\n",
    "    else:\n",
    "        return \"mobula\"\n",
    "\n",
    "def run_data_cycle():\n",
    "    print(\"Starting data cycle...\")\n",
    "    endpoints = fetch_unique_endpoints_from_supabase()\n",
    "    if not endpoints:\n",
    "        print(\"No endpoints fetched from Supabase. Data cycle aborted.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Fetched {len(endpoints)} unique endpoints from Supabase.\")\n",
    "\n",
    "    for endpoint_path in endpoints: # Renamed variable to endpoint_path\n",
    "        provider = determine_provider(endpoint_path) # Pass endpoint_path to determine_provider\n",
    "        if not provider:\n",
    "            print(f\"Could not determine provider for endpoint path: {endpoint_path}. Skipping.\") # Updated log message\n",
    "            continue\n",
    "\n",
    "        base_url = base_urls.get(provider) # Get base URL based on provider\n",
    "        if not base_url:\n",
    "            print(f\"No base URL defined for provider '{provider}'. Skipping endpoint path: {endpoint_path}\") # Updated log message\n",
    "            continue\n",
    "\n",
    "        full_url = base_url + endpoint_path # Construct full URL by joining base URL and endpoint path\n",
    "        headers = header_map.get(provider)\n",
    "        if headers is None:\n",
    "            print(f\"No headers defined for provider '{provider}'. Skipping endpoint: {endpoint_path}\") # Updated log message\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching data from: {full_url} (Provider: {provider})\") # Log full URL\n",
    "\n",
    "        # Check local data first\n",
    "        local_data = load_local_data(provider)\n",
    "        existing_data = next((item for item in local_data if item.get('endpoint') == full_url), None) # Use full_url for local data check\n",
    "\n",
    "        if existing_data and 'response' in existing_data:\n",
    "            print(f\"Using local data for endpoint: {full_url}\") # Use full_url in log message\n",
    "            continue # Skip fetching, use local data - in this data cycle we want to refresh data, so we should always fetch. Removed continue to force refresh\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = requests.get(full_url, headers=headers, timeout=20) # Use full_url for request\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "            response_data = response.json()\n",
    "            end_time = time.time()\n",
    "            fetch_duration = end_time - start_time\n",
    "            print(f\"Successfully fetched data from {full_url} in {fetch_duration:.2f} seconds.\") # Use full_url in log message\n",
    "\n",
    "\n",
    "            # Update local data\n",
    "            endpoint_data_to_save = {'endpoint': full_url, 'response': response_data} # Use full_url for saving\n",
    "            if existing_data:\n",
    "                local_data = [endpoint_data_to_save if item.get('endpoint') == full_url else item for item in local_data] # Use full_url for updating local data\n",
    "            else:\n",
    "                local_data.append(endpoint_data_to_save)\n",
    "            save_local_data(provider, local_data)\n",
    "            print(f\"Data saved to local file for endpoint: {full_url}\") # Use full_url in log message\n",
    "\n",
    "\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP error fetching {full_url}: {http_err}\") # Use full_url in error message\n",
    "        except requests.exceptions.ConnectionError as conn_err:\n",
    "            print(f\"Connection error fetching {full_url}: {conn_err}\") # Use full_url in error message\n",
    "        except requests.exceptions.Timeout as timeout_err:\n",
    "            print(f\"Timeout error fetching {full_url}: {timeout_err}\") # Use full_url in error message\n",
    "        except requests.exceptions.RequestException as req_err:\n",
    "            print(f\"Request exception fetching {full_url}: {req_err}\") # Use full_url in error message\n",
    "        except json.JSONDecodeError as json_err:\n",
    "            print(f\"JSON decode error from {full_url}: {json_err}. Response text was: {response.text[:200]}...\") # Use full_url in error message\n",
    "        except Exception as e:\n",
    "            print(f\"General error fetching or processing {full_url}: {e}\") # Use full_url in error message\n",
    "        time.sleep(1) # Add a small delay to be nice to APIs\n",
    "\n",
    "    print(\"Data cycle finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(MOBULA_DATA_FILE):\n",
    "        os.makedirs(os.path.dirname(MOBULA_DATA_FILE), exist_ok=True) # Ensure directory exists\n",
    "        with open(MOBULA_DATA_FILE, 'w') as f:\n",
    "            json.dump([], f)\n",
    "    if not os.path.exists(LUNARCRUSH_DATA_FILE):\n",
    "        os.makedirs(os.path.dirname(LUNARCRUSH_DATA_FILE), exist_ok=True) # Ensure directory exists\n",
    "        with open(LUNARCRUSH_DATA_FILE, 'w') as f:\n",
    "            json.dump([], f)\n",
    "    run_data_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task sent: 850c27cd-ae60-4eaa-8954-5901da6c7dad\n"
     ]
    }
   ],
   "source": [
    "from celery_app import celery_app\n",
    "\n",
    "# To trigger the task immediately:\n",
    "task = celery_app.send_task('data_cycle.run_data_cycle_task')\n",
    "print(f\"Task sent: {task.id}\")\n",
    "\n",
    "# To get task status later (optional):\n",
    "# result = celery_app.AsyncResult(task.id)\n",
    "# print(f\"Task status: {result.status}\") # e.g., 'PENDING', 'STARTED', 'SUCCESS', 'FAILURE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xade-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
